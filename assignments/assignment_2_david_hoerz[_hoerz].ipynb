{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Shadowjumper3000/ML-fundamentals-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rental Analysis\n",
    "This analysis explores patterns in bike rental data to understand key factors influencing rental behavior. The data is sourced from the UCI Machine Learning Repository and contains hourly rental data spanning two years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "AI was used to write/complete a majority of the scripts in this notebook.\n",
    "The thought process and comments are my own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Kaggle loading here since they offer a free CPU with better specs than mine. If not running on Kaggle this can be disregarded. To run in kaggle simply import notebook and add [BikeData](https://www.kaggle.com/datasets/gabemendez/bike-data) as an input to the dataset section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will automatically save checkpoints to your local machine in the /models directory.\n",
    "Ensure .venv is activated and the required packages are installed before running the code.\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate  # On Windows use .venv\\Scripts\\activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Kaggle environment\n",
    "import os\n",
    "IN_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    # Kaggle-specific paths\n",
    "    data_path = '/kaggle/input/bike-data/CapitalBikeSharing.csv'\n",
    "    checkpoint_dir = '/kaggle/working/models'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Create output directory for downloading models\n",
    "    os.makedirs('/kaggle/working/output', exist_ok=True)\n",
    "\n",
    "    print(\"Running in Kaggle environment.\")\n",
    "    print(\"Data will be loaded from:\", data_path)\n",
    "    print(\"Models will be saved to:\", checkpoint_dir)\n",
    "else:\n",
    "    # Local paths\n",
    "    data_path = '../data/hour.csv'\n",
    "    checkpoint_dir = '../models/checkpoints'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"Running in local environment.\")\n",
    "    print(\"Data will be loaded from:\", data_path)\n",
    "    print(\"Models will be saved to:\", checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_theme()\n",
    "\n",
    "# Load the dataset\n",
    "hour_data = pd.read_csv(data_path)\n",
    "print(\"Data loaded from\" + data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Data Exploration\n",
    "Let's examine the basic structure and statistics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Data Exploration\n",
    "print(\"Dataset Shape:\", hour_data.shape)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(hour_data.info())\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(hour_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Target Variable Analysis\n",
    "Analyzing the distribution of bike rentals (cnt) to understand the general rental patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable Analysis (cnt)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(hour_data['cnt'], kde=True)\n",
    "plt.title('Distribution of Bike Rentals (cnt)')\n",
    "plt.xlabel('Number of Rentals')\n",
    "plt.ylabel('Frequency')\n",
    "print(\"\\nSkewness of cnt:\", hour_data['cnt'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Temporal Pattern Analysis\n",
    "Examining how rental patterns vary by hour and season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Hour analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='hr', y='cnt', data=hour_data)\n",
    "plt.title('Hourly Rental Pattern')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Rentals')\n",
    "plt.show()\n",
    "\n",
    "# Rentals per year\n",
    "# Calculate total rentals per year - safer approach\n",
    "yearly_rentals = hour_data.groupby('yr')['cnt'].sum().reset_index()\n",
    "yearly_rentals['year'] = yearly_rentals['yr'].map({0: '2011', 1: '2012'})\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x='year', y='cnt', data=yearly_rentals, \n",
    "                color=sns.color_palette(\"Blues_d\")[3])\n",
    "plt.title('Total Rentals Per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Rentals')\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height()):,}', \n",
    "               (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha='center', va='bottom',\n",
    "               xytext=(0, 5),\n",
    "               textcoords='offset points')\n",
    "plt.show()\n",
    "\n",
    "# Rentals per month\n",
    "# Calculate total rentals per month - more robust approach\n",
    "monthly_rentals = hour_data.groupby('mnth')['cnt'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='mnth', y='cnt', data=monthly_rentals, \n",
    "                color=sns.color_palette(\"Blues_d\")[3])\n",
    "plt.title('Total Rentals Per Month', pad=15)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Total Rentals')\n",
    "plt.xticks(ticks=range(12), \n",
    "          labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], \n",
    "          rotation=45)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height()):,}', \n",
    "               (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha='center', va='bottom',\n",
    "               xytext=(0, 5),\n",
    "               textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a season-specific visualization to show the distribution\n",
    "# Generate a seasonal visualization with average rentals\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Calculate average rentals per hour by season\n",
    "season_hourly_avg = hour_data.groupby(['season', 'hr'])['cnt'].mean().unstack()\n",
    "\n",
    "# Map season numbers to names for better readability\n",
    "season_names = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "season_hourly_avg.index = [season_names[s] for s in season_hourly_avg.index]\n",
    "\n",
    "# Plot hourly patterns by season\n",
    "for season in season_hourly_avg.index:\n",
    "    plt.plot(season_hourly_avg.columns, season_hourly_avg.loc[season], \n",
    "             label=season, marker='o', markersize=4, linewidth=2, alpha=0.7)\n",
    "\n",
    "plt.title('Hourly Rental Patterns by Season', fontsize=16)\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Average Rentals', fontsize=12)\n",
    "plt.xticks(range(0, 24, 2))\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Season', loc='upper left')\n",
    "\n",
    "# Highlight morning and evening peaks\n",
    "plt.axvspan(7, 9, color='lightyellow', alpha=0.3, label='Morning Peak')\n",
    "plt.axvspan(17, 19, color='lightblue', alpha=0.3, label='Evening Peak')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot monthly total rentals by year\n",
    "monthly_by_year = hour_data.groupby(['yr', 'mnth'])['cnt'].sum().unstack()\n",
    "monthly_by_year.index = ['2011', '2012']  # Convert year index to readable format\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "monthly_by_year.T.plot(kind='bar', figsize=(14, 6))\n",
    "plt.title('Monthly Bike Rentals by Year', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Total Rentals', fontsize=12)\n",
    "plt.xticks(ticks=range(12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.legend(title='Year')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate total rentals per season\n",
    "season_rentals = hour_data.groupby('season')['cnt'].sum().reset_index()\n",
    "\n",
    "# Map season numbers to more readable names\n",
    "season_names_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "season_rentals['season_name'] = season_rentals['season'].map(season_names_map)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='season_name', y='cnt', data=season_rentals,\n",
    "                 palette=\"Blues_d\", order=['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "plt.title('Total Bike Rentals by Season', fontsize=16)\n",
    "plt.xlabel('Season', fontsize=14)\n",
    "plt.ylabel('Total Rentals', fontsize=14)\n",
    "\n",
    "# Add value labels on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height()):,}', \n",
    "               (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha='center', va='bottom',\n",
    "               xytext=(0, 5),\n",
    "               textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that rentals follow an hourly pattern and have increased (nearly doubling) from one year to the next. The hourly peaks will be attributed to commuting/rushour.\n",
    "Rentals per month vary be season it seems, with increasing rents throughout the summer. This will be following the weather and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a cross-tabulation between season and month\n",
    "season_month_crosstab = pd.crosstab(\n",
    "    hour_data['season'],\n",
    "    hour_data['mnth']\n",
    ")\n",
    "\n",
    "# Perform chi-square test for independence\n",
    "chi2, p, dof, expected = chi2_contingency(season_month_crosstab)\n",
    "\n",
    "print(f\"Chi2: {chi2:.2f}\")\n",
    "print(f\"p-value: {p:.10f}\")\n",
    "print(f\"DOF: {dof}\")\n",
    "print(f\"Hypothesis: {'Rejected' if p < 0.05 else 'Not rejected'}\")\n",
    "\n",
    "# Compare correlation with target variable\n",
    "print(\"\\nCorrelation with target variable:\")\n",
    "print(f\"Season-cnt correlation: {hour_data['season'].corr(hour_data['cnt']):.4f}\")\n",
    "print(f\"Month-cnt correlation: {hour_data['mnth'].corr(hour_data['cnt']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the 'Seasons' and 'mnth's are correlated, we will drop the 'mnth' column as this is less correlated with 'cnt' than 'seasons'. I tested with 'mnth' but achieved overall worse results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the mnth column as it's highly correlated with season\n",
    "hour_data = hour_data.drop(columns=['mnth'])\n",
    "print(\"Remaining columns:\", hour_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Holiday and Working Day Analysis\n",
    "Investigating how holidays and working days affect rental patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Holiday analysis at hourly level\n",
    "holiday_labels = {0: 'Non-Holiday', 1: 'Holiday'}\n",
    "sns.boxplot(x='holiday', y='cnt', data=hour_data, ax=ax1)\n",
    "ax1.set_title('Hourly Rentals: Holiday vs Non-Holiday')\n",
    "ax1.set_xticklabels([holiday_labels[i] for i in [0, 1]])\n",
    "ax1.set_xlabel('Day Type')\n",
    "ax1.set_ylabel('Hourly Rentals')\n",
    "\n",
    "# Working day analysis at hourly level\n",
    "workingday_labels = {0: 'Non-Working Day', 1: 'Working Day'}\n",
    "sns.boxplot(x='workingday', y='cnt', data=hour_data, ax=ax2)\n",
    "ax2.set_title('Hourly Rentals: Working vs Non-Working Days')\n",
    "ax2.set_xticklabels([workingday_labels[i] for i in [0, 1]])\n",
    "ax2.set_xlabel('Day Type')\n",
    "ax2.set_ylabel('Hourly Rentals')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On holidays, rentals are significantly lower, while working days show a more consistent rental pattern. This suggests that bike rentals are more popular during weekdays and less so on holidays.\n",
    "Additionally there are many more outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create day of week visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Calculate average rentals by day of week\n",
    "weekday_rentals = hour_data.groupby('weekday')['cnt'].mean().reset_index()\n",
    "\n",
    "# Map weekday numbers to names for better readability\n",
    "weekday_names = {\n",
    "    0: 'Sunday',\n",
    "    1: 'Monday',\n",
    "    2: 'Tuesday',\n",
    "    3: 'Wednesday',\n",
    "    4: 'Thursday',\n",
    "    5: 'Friday',\n",
    "    6: 'Saturday'\n",
    "}\n",
    "weekday_rentals['day_name'] = weekday_rentals['weekday'].map(weekday_names)\n",
    "\n",
    "# Create bar plot with improved styling\n",
    "ax = sns.barplot(x='day_name', y='cnt', data=weekday_rentals, \n",
    "                order=[weekday_names[i] for i in range(7)],\n",
    "                palette='Blues_d')\n",
    "plt.title('Average Hourly Bike Rentals by Day of Week', fontsize=16, pad=20)\n",
    "plt.xlabel('Day of Week', fontsize=14)\n",
    "plt.ylabel('Average Hourly Rentals', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.1f}', \n",
    "               (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "               ha='center', va='bottom',\n",
    "               xytext=(0, 5),\n",
    "               textcoords='offset points')\n",
    "\n",
    "# Add weekday vs weekend comparison\n",
    "weekday_mask = hour_data['weekday'].isin([1, 2, 3, 4, 5])\n",
    "weekend_mask = hour_data['weekday'].isin([0, 6])\n",
    "weekday_avg = hour_data[weekday_mask]['cnt'].mean()\n",
    "weekend_avg = hour_data[weekend_mask]['cnt'].mean()\n",
    "diff_pct = ((weekday_avg - weekend_avg) / weekend_avg) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that day of the week does not have a significant impact on rentals, this will be due to more leisure rentals on weekends and holidays, whereas workdays are more commuter based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze weekday effect on bike rentals (cnt) with hourly patterns by day\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Create hourly patterns by day of week\n",
    "hourly_weekday_data = hour_data.pivot_table(\n",
    "    values='cnt', \n",
    "    index='hr', \n",
    "    columns='weekday', \n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Map weekday numbers to names for better readability\n",
    "hourly_weekday_data.columns = [weekday_names[day] for day in hourly_weekday_data.columns]\n",
    "\n",
    "# Plot hourly patterns by day of week\n",
    "for day in hourly_weekday_data.columns:\n",
    "    plt.plot(hourly_weekday_data.index, hourly_weekday_data[day], \n",
    "             label=day, marker='o', markersize=5, alpha=0.7)\n",
    "\n",
    "# Add highlights for peak hours\n",
    "plt.axvspan(7, 9, color='lightblue', alpha=0.3, label='Morning Peak')\n",
    "plt.axvspan(16, 19, color='lightyellow', alpha=0.3, label='Evening Peak')\n",
    "\n",
    "plt.title('Hourly Rental Patterns by Day of Week', fontsize=16)\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Average Rentals', fontsize=12)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Day of Week', loc='upper center', bbox_to_anchor=(0.5, -0.15), \n",
    "           fancybox=True, shadow=True, ncol=4)\n",
    "\n",
    "# Calculate and display correlation between weekday and cnt\n",
    "weekday_cnt_corr = hour_data['weekday'].corr(hour_data['cnt'])\n",
    "plt.annotate(f'Correlation between weekday and cnt: {weekday_cnt_corr:.3f}',\n",
    "            xy=(0.5, 0.97), xycoords='axes fraction',\n",
    "            ha='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.8))\n",
    "plt.annotate(f'Correlation between workingday and cnt: {hour_data[\"workingday\"].corr(hour_data[\"cnt\"]):.3f}',\n",
    "            xy=(0.5, 0.92), xycoords='axes fraction',\n",
    "            ha='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.8))\n",
    "plt.annotate(f'Correlation between holiday and cnt: {hour_data[\"holiday\"].corr(hour_data[\"cnt\"]):.3f}',\n",
    "            xy=(0.5, 0.87), xycoords='axes fraction',\n",
    "            ha='center', fontsize=12,\n",
    "            bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the spread of rentals on weekday vs weekend, we will drop the 'weekday' column as it is less correlated with 'cnt' than 'workingday'. Additionally for model simplicity it only requires learning binary classification of work / !work days. Rather than learning 7 classes of weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the weekday column as it's less correlated with 'cnt' than 'workingday'\n",
    "hour_data = hour_data.drop(columns=['weekday'])\n",
    "print(f\"'weekday' column dropped. Remaining columns: {hour_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Calculate basic statistics for workingday vs cnt\n",
    "workingday_stats = hour_data.groupby('workingday')['cnt'].agg(['mean', 'median', 'std', 'count'])\n",
    "workingday_1 = hour_data[hour_data['workingday'] == 1]['cnt']\n",
    "workingday_0 = hour_data[hour_data['workingday'] == 0]['cnt']\n",
    "workingday_ttest = stats.ttest_ind(workingday_1, workingday_0, equal_var=False)\n",
    "\n",
    "# Calculate basic statistics for holiday vs cnt\n",
    "holiday_stats = hour_data.groupby('holiday')['cnt'].agg(['mean', 'median', 'std', 'count'])\n",
    "holiday_1 = hour_data[hour_data['holiday'] == 1]['cnt']\n",
    "holiday_0 = hour_data[hour_data['holiday'] == 0]['cnt']\n",
    "holiday_ttest = stats.ttest_ind(holiday_1, holiday_0, equal_var=False)\n",
    "\n",
    "# Print results\n",
    "print(\"WORKINGDAY STATISTICS:\")\n",
    "print(workingday_stats)\n",
    "print(f\"T-test: t={workingday_ttest.statistic:.4f}, p={workingday_ttest.pvalue:.8f}\")\n",
    "\n",
    "print(\"\\nHOLIDAY STATISTICS:\")\n",
    "print(holiday_stats)\n",
    "print(f\"T-test: t={holiday_ttest.statistic:.4f}, p={holiday_ttest.pvalue:.8f}\")\n",
    "\n",
    "# Calculate hourly volume\n",
    "hourly_workingday = hour_data.groupby(['workingday'])['cnt'].mean()\n",
    "hourly_holiday = hour_data.groupby(['holiday'])['cnt'].mean()\n",
    "\n",
    "print(f\"\\nAVERAGE HOURLY RENTALS:\")\n",
    "print(f\"Working days: {hourly_workingday[1]:.2f}\")\n",
    "print(f\"Non-working days: {hourly_workingday[0]:.2f}\")\n",
    "print(f\"Holidays: {hourly_holiday[1]:.2f}\")\n",
    "print(f\"Non-holidays: {hourly_holiday[0]:.2f}\")\n",
    "\n",
    "# Calculate correlation with target\n",
    "print(f\"\\nCORRELATION WITH TARGET:\")\n",
    "print(f\"Workingday-cnt correlation: {hour_data['workingday'].corr(hour_data['cnt']):.4f}\")\n",
    "print(f\"Holiday-cnt correlation: {hour_data['holiday'].corr(hour_data['cnt']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to 'workingday' and 'holiday' being correlated, we will drop the 'holiday' column to avoid redundancy and aid in model interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the holiday column\n",
    "hour_data = hour_data.drop(columns=['holiday'])\n",
    "print(f\"'holiday' column dropped. Remaining columns: {hour_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Weather Impact Analysis\n",
    "Analyzing how different weather conditions affect rental behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weather situation mapping\n",
    "weather_labels = {\n",
    "    1: 'Clear/Partly Cloudy',\n",
    "    2: 'Mist/Cloudy',\n",
    "    3: 'Light Rain/Snow',\n",
    "    4: 'Heavy Rain/Snow'\n",
    "}\n",
    "\n",
    "# Temperature vs Count with improved styling\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='temp', y='cnt', data=hour_data, alpha=0.5)\n",
    "plt.title('Impact of Temperature on Bike Rentals', pad=15)\n",
    "plt.xlabel('Temperature (Normalized 0-1 scale)')\n",
    "plt.ylabel('Number of Hourly Rentals')\n",
    "\n",
    "# Add trend line\n",
    "sns.regplot(x='temp', y='cnt', data=hour_data, scatter=False, color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Weather Situation vs Count with descriptive labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='weathersit', y='cnt', data=hour_data)\n",
    "plt.title('Impact of Weather Conditions on Bike Rentals', pad=15)\n",
    "plt.xlabel('Weather Condition')\n",
    "plt.ylabel('Number of Hourly Rentals')\n",
    "\n",
    "# Update x-axis labels with weather descriptions\n",
    "plt.xticks(range(len(weather_labels)), \n",
    "          [weather_labels[i] for i in range(1, 5)], \n",
    "          rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weathersituation varies greatly, as such we wil have to make it easier interpretable for the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rental distribution statistics\n",
    "print(\"1. Distribution Statistics:\")\n",
    "print(f\"Mean rentals: {hour_data['cnt'].mean():.2f}\")\n",
    "print(f\"Median rentals: {hour_data['cnt'].median():.2f}\")\n",
    "print(f\"Skewness: {hour_data['cnt'].skew():.2f}\")\n",
    "\n",
    "# Calculate peak hours statistics\n",
    "hourly_avg = hour_data.groupby('hr')['cnt'].mean()\n",
    "peak_hours = hourly_avg.nlargest(3)\n",
    "print(\"\\n2. Peak Hours:\")\n",
    "print(peak_hours)\n",
    "\n",
    "# Calculate weather correlations\n",
    "print(\"\\n3. Weather Correlations:\")\n",
    "print(f\"Temperature correlation: {hour_data['cnt'].corr(hour_data['temp']):.2f}\")\n",
    "print(f\"Humidity correlation: {hour_data['cnt'].corr(hour_data['hum']):.2f}\")\n",
    "print(f\"Wind speed correlation: {hour_data['cnt'].corr(hour_data['windspeed']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between temp and atemp\n",
    "temp_correlation = hour_data['temp'].corr(hour_data['atemp'])\n",
    "\n",
    "# Create visualization to show relationship\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=hour_data, x='temp', y='atemp', alpha=0.5)\n",
    "plt.title(f'Temperature vs Apparent Temperature\\nCorrelation: {temp_correlation:.3f}')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Apparent Temperature (Feels Like)')\n",
    "\n",
    "# Print analysis\n",
    "print(f\"Correlation between temp and atemp: {temp_correlation:.3f}\")\n",
    "\n",
    "# Check their individual correlations with the target variable\n",
    "temp_target_corr = hour_data['temp'].corr(hour_data['cnt'])\n",
    "atemp_target_corr = hour_data['atemp'].corr(hour_data['cnt'])\n",
    "\n",
    "print(\"\\nCorrelations with rental count (cnt):\")\n",
    "print(f\"Temperature: {temp_target_corr:.3f}\")\n",
    "print(f\"Apparent Temperature: {atemp_target_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will dorp the 'temp' column as it is less correlated with 'cnt' than 'atemp'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_data = hour_data.drop(columns=['atemp'])\n",
    "print(\"Columns remaining after dropping 'atemp':\", hour_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Feature Correlation Analysis\n",
    "Examining relationships between numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the 'instant' column as it is not needed for our analysis. The 'instant' column is an index that we will not use in our analysis.\n",
    "'casual' and 'registered' columns are also dropped as they are only gathered after bike rental. We will only use the 'cnt' column as our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop index-like or redundant columns\n",
    "columns_to_drop = ['instant', 'casual', 'registered']\n",
    "\n",
    "# Drop columns and create clean dataset\n",
    "hour_data_clean = hour_data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(\"\\nColumns dropped:\", columns_to_drop)\n",
    "print(\"Remaining columns:\", hour_data_clean.columns.tolist())\n",
    "\n",
    "# Update our working dataset\n",
    "hour_data = hour_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels for all columns\n",
    "feature_labels = {\n",
    "    'cnt': 'Total Rentals',\n",
    "    'season': 'Season',\n",
    "    'yr': 'Year',\n",
    "    'hr': 'Hour', \n",
    "    'workingday': 'Working Day',\n",
    "    'weathersit': 'Weather',\n",
    "    'temp': 'Temperature',\n",
    "    'hum': 'Humidity',\n",
    "    'windspeed': 'Wind Speed',\n",
    "}\n",
    "\n",
    "# Select all numeric columns for correlation analysis\n",
    "# Exclude 'instant' (index) and 'dteday' (date) as they're not meaningful for correlation\n",
    "numeric_columns = [ 'cnt', 'season', 'yr', 'hr', 'workingday', 'weathersit', \n",
    "                  'temp', 'hum', 'windspeed']\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = hour_data[numeric_columns].corr()\n",
    "\n",
    "# Plot correlation matrix with improved readability\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            fmt='.2f',\n",
    "            xticklabels=[feature_labels[col] for col in numeric_columns],\n",
    "            yticklabels=[feature_labels[col] for col in numeric_columns])\n",
    "\n",
    "plt.title('Correlation Matrix of All Numerical Features', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top correlations with the target variable (cnt)\n",
    "correlations_with_target = correlation_matrix['cnt'].drop('cnt').sort_values(ascending=False)\n",
    "print(\"Top correlations with total rentals (cnt):\")\n",
    "for col, corr in correlations_with_target.items():\n",
    "    print(f\"{feature_labels[col]}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any remaining problematic columns\n",
    "df_clean = hour_data\n",
    "del hour_data\n",
    "\n",
    "print(\"Final columns in cleaned dataset:\", df_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our data into three sets:\n",
    "- Training set (70%): Used to train the model\n",
    "- Validation set (15%): Used to tune hyperparameters and evaluate model during training\n",
    "- Test set (15%): Used for final model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Anchor Data Split for Temporal Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure the data is sorted chronologically\n",
    "if 'dteday' in df_clean.columns:\n",
    "    df_clean = df_clean.sort_values(by=['dteday', 'hr'])\n",
    "    print(f\"Data sorted by date and hour, spanning from {df_clean['dteday'].min()} to {df_clean['dteday'].max()}\")\n",
    "    \n",
    "    # Remove the dteday column after using it for sorting\n",
    "    df_clean = df_clean.drop(columns=['dteday'])\n",
    "    print(\"Removed 'dteday' column as it's only used for indexing\")\n",
    "else:\n",
    "    # If no date column exists, we'll assume the data is already in chronological order\n",
    "    print(\"No date column found, assuming data is already in chronological order\")\n",
    "\n",
    "# Define split ratios for train, validation, and test (60/20/20)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calculate split points\n",
    "n_samples = len(df_clean)\n",
    "train_size = int(train_ratio * n_samples)\n",
    "val_size = int(val_ratio * n_samples)\n",
    "\n",
    "# Split the data chronologically\n",
    "X = df_clean.drop(columns=['cnt'])\n",
    "y = df_clean['cnt']\n",
    "\n",
    "# Create train, validation, and test sets based on indices\n",
    "X_train = X.iloc[:train_size]\n",
    "y_train = y.iloc[:train_size]\n",
    "\n",
    "X_val = X.iloc[train_size:train_size+val_size]\n",
    "y_val = y.iloc[train_size:train_size+val_size]\n",
    "\n",
    "X_test = X.iloc[train_size+val_size:]\n",
    "y_test = y.iloc[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the sizes of each set\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/n_samples:.1%})\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/n_samples:.1%})\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/n_samples:.1%})\")\n",
    "\n",
    "# Visualize the rolling window split\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create a dataframe with indices and target values for visualization\n",
    "full_data = pd.DataFrame({\n",
    "    'index': range(len(y)),\n",
    "    'target': y.values,\n",
    "    'set': ['train'] * train_size + ['validation'] * val_size + ['test'] * (n_samples - train_size - val_size)\n",
    "})\n",
    "\n",
    "# Plot the data color-coded by set\n",
    "colors = {'train': 'blue', 'validation': 'green', 'test': 'red'}\n",
    "sets = ['train', 'validation', 'test']\n",
    "labels = ['Training Set', 'Validation Set', 'Test Set']\n",
    "\n",
    "# Create scatter plot with time index vs target value\n",
    "for i, s in enumerate(sets):\n",
    "    subset = full_data[full_data['set'] == s]\n",
    "    plt.scatter(subset['index'], subset['target'], \n",
    "                color=colors[s], alpha=0.5, label=labels[i])\n",
    "\n",
    "# Add vertical lines to mark the split points\n",
    "plt.axvline(x=train_size, color='black', linestyle='--', label='Split Points')\n",
    "plt.axvline(x=train_size+val_size, color='black', linestyle='--')\n",
    "\n",
    "plt.title('Rolling Anchor Split of Bike Rental Data (60/20/20)')\n",
    "plt.xlabel('Time Index')\n",
    "plt.ylabel('Number of Rentals (cnt)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Check for temporal patterns in each split\n",
    "if 'hr' in X.columns:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Hourly patterns in each split\n",
    "    for i, (X_set, y_set, label, color) in enumerate(zip([X_train, X_val, X_test], \n",
    "                                                      [y_train, y_val, y_test],\n",
    "                                                      ['Training', 'Validation', 'Test'],\n",
    "                                                      ['blue', 'green', 'red'])):\n",
    "        hourly_avg = pd.DataFrame({'hr': X_set['hr'], 'cnt': y_set}).groupby('hr').mean()\n",
    "        plt.plot(hourly_avg.index, hourly_avg['cnt'], \n",
    "                 label=label, color=color, marker='o', markersize=5, alpha=0.7)\n",
    "    \n",
    "    plt.title('Hourly Rental Patterns Across Splits')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Average Rentals')\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that due to the temporal ordering of the data we will have issues with the modell underpredicting, I have made the training set larger and grow more into the second year to help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Columns after splitting:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's identify our feature types\n",
    "binary_features = ['workingday']\n",
    "numeric_features = ['temp', 'hum', 'windspeed']\n",
    "categorical_features = ['weathersit']\n",
    "cyclical_features = ['hr', 'season']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Weather consists of multiple features, I will create multiple columns to represent the weather conditions. This will help the model learn better and make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the one-hot encoding of weather with ordinal features that have clear semantic meaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to create weather features with semantic meaning\n",
    "def create_weather_features(df):\n",
    "    \"\"\"\n",
    "    Creates meaningful ordinal features from weathersit.\n",
    "    Weather codes: 1=Clear, 2=Mist/Cloudy, 3=Light Rain/Snow, 4=Heavy Rain/Snow\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the weathersit column\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with added weather features\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Create ordinal weather severity score (0-1 scale)\n",
    "    weather_severity_map = {\n",
    "        1: 0.0,   # Clear/Partly cloudy - optimal for biking\n",
    "        2: 0.33,  # Mist/Cloudy - slightly worse\n",
    "        3: 0.67,  # Light Rain/Snow - significantly worse\n",
    "        4: 1.0    # Heavy Rain/Snow - worst for biking\n",
    "    }\n",
    "    df_processed['weather_severity'] = df_processed['weathersit'].map(weather_severity_map)\n",
    "    \n",
    "    # Binary features with clear semantic meaning\n",
    "    # Is it raining/snowing?\n",
    "    df_processed['is_precipitation'] = (df_processed['weathersit'] >= 3).astype(int)\n",
    "    \n",
    "    # Is visibility reduced?\n",
    "    df_processed['reduced_visibility'] = (df_processed['weathersit'] >= 2).astype(int)\n",
    "    \n",
    "    # Drop the original weathersit column\n",
    "    df_processed = df_processed.drop(columns=['weathersit'])\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Apply weather feature transformation to each dataset\n",
    "print(\"Replacing one-hot encoding with ordinal weather features...\")\n",
    "X_train_processed = create_weather_features(X_train)\n",
    "X_val_processed = create_weather_features(X_val)\n",
    "X_test_processed = create_weather_features(X_test)\n",
    "\n",
    "print(\"Created the following weather features:\")\n",
    "print(\"- 'weather_severity': Continuous score from 0.0 (clear) to 1.0 (heavy rain/snow)\")\n",
    "print(\"- 'is_precipitation': Binary indicator for rain or snow\")\n",
    "print(\"- 'reduced_visibility': Binary indicator for mist, clouds, or precipitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a new feature called 'is_rush_hour' to capture the impact of rush hours on bike rentals. This feature will be a binary variable indicating whether the hour is during peak commuting times (7-9 AM and 5-7 PM). This will help us understand how rush hours affect bike rentals and allow us to analyze the impact of commuting patterns on rental behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to identify rush hours on working days\n",
    "def is_rush_hour(hour, workingday):\n",
    "    \"\"\"\n",
    "    Determines if a given hour is during rush hour on a working day.\n",
    "    Rush hours are defined as 7-9 AM and 5-7 PM (17-19) on working days.\n",
    "    \n",
    "    Parameters:\n",
    "    - hour: Integer representing the hour of day (0-23)\n",
    "    - workingday: Binary indicator if it's a working day (1) or not (0)\n",
    "    \n",
    "    Returns:\n",
    "    - 1 if it's rush hour on a working day, 0 otherwise\n",
    "    \"\"\"\n",
    "    morning_rush = (7 <= hour <= 9)\n",
    "    evening_rush = (17 <= hour <= 19)\n",
    "    return 1 if (morning_rush or evening_rush) and workingday == 1 else 0\n",
    "\n",
    "# Apply the function to create the new feature in all data splits\n",
    "def apply_rush_hour(row):\n",
    "    return is_rush_hour(row['hr'], row['workingday'])\n",
    "\n",
    "X_train_processed['is_rush_hour'] = [apply_rush_hour(row) for _, row in X_train_processed.iterrows()]\n",
    "X_val_processed['is_rush_hour'] = [apply_rush_hour(row) for _, row in X_val_processed.iterrows()]\n",
    "X_test_processed['is_rush_hour'] = [apply_rush_hour(row) for _, row in X_test_processed.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cyclical features like hour and month, we will use sine and cosine transformations to capture their cyclical nature. This will help the model learn better and make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to convert cyclical features to sine and cosine components\n",
    "def create_cyclical_features(df, col, period):\n",
    "    \"\"\"\n",
    "    Creates sine and cosine transformations for cyclical features.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the feature\n",
    "    - col: Name of the cyclical feature column\n",
    "    - period: The period of the cycle (e.g., 24 for hours, 4 for seasons)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with added sine and cosine features\n",
    "    \"\"\"\n",
    "    # Create new column names\n",
    "    sin_col = f'{col}_sin'\n",
    "    cos_col = f'{col}_cos'\n",
    "    \n",
    "    # Calculate sine and cosine values\n",
    "    df[sin_col] = np.sin(2 * np.pi * df[col] / period)\n",
    "    df[cos_col] = np.cos(2 * np.pi * df[col] / period)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process each dataset - Training set\n",
    "print(\"Processing training set...\")\n",
    "# Transform hour into cyclical features (period = 24 hours)\n",
    "X_train_processed = create_cyclical_features(X_train_processed, 'hr', 24)\n",
    "# Transform season into cyclical features (period = 4 moths)\n",
    "X_train_processed = create_cyclical_features(X_train_processed, 'season', 4)\n",
    "\n",
    "# Process validation set\n",
    "print(\"Processing validation set...\")\n",
    "X_val_processed = create_cyclical_features(X_val_processed, 'hr', 24)\n",
    "X_val_processed = create_cyclical_features(X_val_processed, 'season', 4)\n",
    "\n",
    "# Process test set\n",
    "print(\"Processing test set...\")\n",
    "X_test_processed = create_cyclical_features(X_test_processed, 'hr', 24)\n",
    "X_test_processed = create_cyclical_features(X_test_processed, 'season', 4)\n",
    "\n",
    "# Drop the original columns after creating the cyclical features\n",
    "X_train_processed = X_train_processed.drop(columns=['hr', 'season'])\n",
    "X_val_processed = X_val_processed.drop(columns=['hr', 'season'])\n",
    "X_test_processed = X_test_processed.drop(columns=['hr', 'season'])\n",
    "\n",
    "# Confirm the new features were created and original ones removed\n",
    "print(f\"New cyclical features created: 'hr_sin', 'hr_cos', 'season_sin', 'season_cos'\")\n",
    "print(f\"Original 'hr' and 'season' columns dropped\")\n",
    "print(f\"Training set shape: {X_train_processed.shape}\")\n",
    "print(f\"Validation set shape: {X_val_processed.shape}\")\n",
    "print(f\"Test set shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For numerical features, we will use StandardScaler to scale the features to a range of [0, 1]. This will help the model learn better and make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric features using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to scale numeric features\n",
    "def scale_numeric_features(train_df, val_df, test_df, numeric_cols):\n",
    "    \"\"\"\n",
    "    Scales numeric features using StandardScaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df: Training DataFrame\n",
    "    - val_df: Validation DataFrame\n",
    "    - test_df: Test DataFrame\n",
    "    - numeric_cols: List of numeric columns to scale\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple of (scaled train_df, scaled val_df, scaled test_df, scaler)\n",
    "    \"\"\"\n",
    "    # Make copies to avoid modifying originals\n",
    "    train_scaled = train_df.copy()\n",
    "    val_scaled = val_df.copy()\n",
    "    test_scaled = test_df.copy()\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler on training data only\n",
    "    scaler.fit(train_df[numeric_cols])\n",
    "    \n",
    "    # Transform all datasets\n",
    "    train_scaled[numeric_cols] = scaler.transform(train_df[numeric_cols])\n",
    "    val_scaled[numeric_cols] = scaler.transform(val_df[numeric_cols])\n",
    "    test_scaled[numeric_cols] = scaler.transform(test_df[numeric_cols])\n",
    "    \n",
    "    print(f\"Scaled numeric features: {', '.join(numeric_cols)}\")\n",
    "    print(f\"Scaling statistics (mean, std):\")\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        print(f\"  - {col}: mean={scaler.mean_[i]:.4f}, std={scaler.scale_[i]:.4f}\")\n",
    "    \n",
    "    return train_scaled, val_scaled, test_scaled, scaler\n",
    "\n",
    "# Apply scaling to the datasets\n",
    "print(\"Applying StandardScaler to numeric features...\")\n",
    "X_train_processed, X_val_processed, X_test_processed, feature_scaler = scale_numeric_features(\n",
    "    X_train_processed, X_val_processed, X_test_processed, numeric_features\n",
    ")\n",
    "\n",
    "# Save the scaler for future use (optional)\n",
    "import joblib\n",
    "scaler_path = os.path.join(checkpoint_dir, 'feature_scaler.joblib')\n",
    "joblib.dump(feature_scaler, scaler_path)\n",
    "print(f\"Feature scaler saved to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Columns after processing:\")\n",
    "print(X_train_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Linear Regression following the given instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize and train the model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train_processed)\n",
    "y_val_pred = lr_model.predict(X_val_processed)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred),\n",
    "    'R2': r2_score(y_val, y_val_pred)\n",
    "}\n",
    "\n",
    "print(\"Validation Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals = y_val - y_val_pred\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.xlabel('Residual Value')\n",
    "plt.show()\n",
    "\n",
    "# Plot predicted vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred, alpha=0.5)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', linewidth=2)\n",
    "plt.title('Predicted vs. Actual Values')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Analyze bias and variance\n",
    "print(\"\\nBias-Variance Analysis:\")\n",
    "print(f\"Training R2: {r2_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Validation R2: {r2_score(y_val, y_val_pred):.4f}\")\n",
    "\n",
    "# Save the initial Linear Regression model\n",
    "import pickle\n",
    "lr_model_path = os.path.join(checkpoint_dir, 'lr_model_initial.pkl')\n",
    "with open(lr_model_path, 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "print(f\"Initial Linear Regression model saved to {lr_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its heavily under estimating the bike rentals. This is likely because its not capturing the relationship of the years on the 'cnt' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Random Forest Regression following the given instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train_processed)\n",
    "y_val_pred_rf = rf_model.predict(X_val_processed)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_rf = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred_rf),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred_rf),\n",
    "    'R2': r2_score(y_val, y_val_pred_rf)\n",
    "}\n",
    "\n",
    "print(\"Random Forest Validation Metrics:\")\n",
    "for metric, value in metrics_rf.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Feature importance plot - with fix for missing feature_names\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Use the column names from X_train_processed instead of undefined feature_names\n",
    "feature_importance = pd.Series(rf_model.feature_importances_, index=X_train_processed.columns)\n",
    "feature_importance.nlargest(10).plot(kind='barh')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.show()\n",
    "\n",
    "# Compare with baseline\n",
    "print(\"\\nComparison with Linear Regression:\")\n",
    "for metric in metrics.keys():\n",
    "    improvement = (metrics_rf[metric] - metrics[metric]) / abs(metrics[metric]) * 100\n",
    "    print(f\"{metric} improvement: {improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as though 'is_rush_hour' is a very important feature for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Random Forest model\n",
    "import pickle\n",
    "\n",
    "# Save the current model if tuned version isn't available yet\n",
    "rf_model_path = os.path.join(checkpoint_dir, 'rf_model_initial.pkl')\n",
    "with open(rf_model_path, 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "\n",
    "print(f\"Random Forest model saved to {rf_model_path}\")\n",
    "\n",
    "# We'll save the tuned version later after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize and train the model with verbose logging\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_model = XGBRegressor(\n",
    "    random_state=42, \n",
    "    verbose=1,\n",
    "    eval_metric=['rmse', 'mae'],\n",
    "    early_stopping_rounds=10  # Move this parameter here\n",
    ")\n",
    "xgb_model.fit(\n",
    "    X_train_processed, \n",
    "    y_train, \n",
    "    eval_set=[(X_train_processed, y_train), (X_val_processed, y_val)],\n",
    "    verbose=True  # Keep this to see progress during training\n",
    ")\n",
    "\n",
    "# Calculate training time\n",
    "training_time = time.time() - start_time\n",
    "print(f\"XGBoost training completed in {training_time:.2f} seconds\\n\")\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_processed)\n",
    "y_val_pred_xgb = xgb_model.predict(X_val_processed)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "train_metrics = {\n",
    "    'MSE': mean_squared_error(y_train, y_train_pred_xgb),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred_xgb)),\n",
    "    'MAE': mean_absolute_error(y_train, y_train_pred_xgb),\n",
    "    'R2': r2_score(y_train, y_train_pred_xgb),\n",
    "    'Explained Variance': explained_variance_score(y_train, y_train_pred_xgb)\n",
    "}\n",
    "\n",
    "val_metrics = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred_xgb),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_val, y_val_pred_xgb)),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred_xgb),\n",
    "    'R2': r2_score(y_val, y_val_pred_xgb),\n",
    "    'Explained Variance': explained_variance_score(y_val, y_val_pred_xgb)\n",
    "}\n",
    "\n",
    "# Print metrics in a formatted table\n",
    "print(\"XGBoost Performance Metrics:\")\n",
    "print(f\"{'Metric':<20} {'Training':<15} {'Validation':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for metric in train_metrics.keys():\n",
    "    print(f\"{metric:<20} {train_metrics[metric]:<15.4f} {val_metrics[metric]:<15.4f}\")\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Use column names from the training data instead of the undefined feature_names\n",
    "feature_importance = pd.Series(xgb_model.feature_importances_, \n",
    "                              index=X_train_processed.columns).sort_values(ascending=False)\n",
    "ax = feature_importance.head(15).plot(kind='barh', \n",
    "                                    color=sns.color_palette(\"viridis\", len(feature_importance.head(15))))\n",
    "plt.title('Top 15 Most Important Features in XGBoost Model', fontsize=14)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add value annotations to the bars\n",
    "for i, v in enumerate(feature_importance.head(15)):\n",
    "    ax.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals_xgb = y_val - y_val_pred_xgb\n",
    "sns.histplot(residuals_xgb, kde=True, bins=30, color='steelblue')\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "plt.title('Distribution of XGBoost Residuals', fontsize=14)\n",
    "plt.xlabel('Residual Value', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot of actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred_xgb, alpha=0.5, color='steelblue')\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
    "plt.title('XGBoost: Actual vs Predicted Values', fontsize=14)\n",
    "plt.xlabel('Actual', fontsize=12)\n",
    "plt.ylabel('Predicted', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare with previous models\n",
    "print(\"\\nComparison with Previous Models:\")\n",
    "for metric in ['MSE', 'MAE', 'R2']:\n",
    "    improvement_rf = (val_metrics[metric] - metrics_rf[metric]) / abs(metrics_rf[metric]) * 100\n",
    "    improvement_lr = (val_metrics[metric] - metrics[metric]) / abs(metrics[metric]) * 100\n",
    "    \n",
    "    # Display with colored text for better visualization\n",
    "    rf_status = \"✓ Better\" if ((metric == 'R2' and improvement_rf > 0) or \n",
    "                               (metric != 'R2' and improvement_rf < 0)) else \"✗ Worse\"\n",
    "    lr_status = \"✓ Better\" if ((metric == 'R2' and improvement_lr > 0) or \n",
    "                              (metric != 'R2' and improvement_lr < 0)) else \"✗ Worse\"\n",
    "    \n",
    "    print(f\"{metric} compared to Random Forest: {improvement_rf:.2f}% ({rf_status})\")\n",
    "    print(f\"{metric} compared to Linear Regression: {improvement_lr:.2f}% ({lr_status})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks very good already, might nott need to do anything else\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets tune for hyperparameters for the Gradient Boosting model to see if we can improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for hyperparameter tuning\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence, plot_objective\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('hyperparameter_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter search spaces\n",
    "logger.info(\"Starting hyperparameter tuning process\")\n",
    "print(\"Defining parameter search spaces...\")\n",
    "\n",
    "# Random Forest parameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': [0.5, 0.7, 1.0, 'sqrt', 'log2', None]\n",
    "}\n",
    "logger.info(f\"Random Forest parameters to tune: {', '.join(rf_param_grid.keys())}\")\n",
    "print(\"Random Forest parameters to tune:\", \", \".join(rf_param_grid.keys()))\n",
    "\n",
    "# Define XGBoost search space for BayesSearchCV\n",
    "xgb_search_space = {\n",
    "    'learning_rate': Real(0.01, 0.3, prior='log-uniform', name='learning_rate'),\n",
    "    'n_estimators': Integer(50, 200, name='n_estimators'),\n",
    "    'max_depth': Integer(3, 10, name='max_depth'),\n",
    "    'subsample': Real(0.6, 1.0, name='subsample'),\n",
    "    'colsample_bytree': Real(0.6, 1.0, name='colsample_bytree'),\n",
    "    'gamma': Real(0, 1, name='gamma'),\n",
    "    'min_child_weight': Integer(1, 10, name='min_child_weight')\n",
    "}\n",
    "logger.info(f\"XGBoost parameters to tune: {', '.join(xgb_search_space.keys())}\")\n",
    "print(\"XGBoost parameters to tune:\", \", \".join(xgb_search_space.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Random Forest tuning with RandomizedSearchCV\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting Random Forest hyperparameter tuning...\")\n",
    "logger.info(\"Starting Random Forest hyperparameter tuning\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Create RF search\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "logger.info(f\"Starting RF RandomizedSearchCV with {rf_random_search.n_iter} iterations\")\n",
    "print(f\"Running {rf_random_search.n_iter} iterations of Random Forest hyperparameter search...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Tuning with BayesSearchCV\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Starting XGBoost hyperparameter tuning with Bayesian Optimization...\")\n",
    "logger.info(\"Starting XGBoost hyperparameter tuning with Bayesian Optimization\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize BayesSearchCV for XGBoost\n",
    "xgb_bayes_search = BayesSearchCV(\n",
    "    XGBRegressor(random_state=42),\n",
    "    search_spaces=xgb_search_space,\n",
    "    n_iter=50,  # Number of optimization iterations\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    n_points=3  # Number of parameter settings evaluated in parallel\n",
    ")\n",
    "\n",
    "\n",
    "logger.info(f\"Starting XGB BayesSearchCV with {xgb_bayes_search.n_iter} iterations\")\n",
    "print(f\"Running {xgb_bayes_search.n_iter} iterations of XGBoost Bayesian optimization...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fit the Random Forest model\n",
    "    rf_random_search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Log results from each iteration for analysis\n",
    "    rf_results = pd.DataFrame(rf_random_search.cv_results_)\n",
    "    \n",
    "    # Log the top 5 best performing parameter combinations\n",
    "    logger.info(\"Top 5 Random Forest parameter combinations:\")\n",
    "    top_results = rf_results.sort_values('mean_test_score', ascending=False).head(5)\n",
    "    for i, row in top_results.iterrows():\n",
    "        logger.info(f\"Rank {i+1}: Score = {-row['mean_test_score']:.4f}, Params = {row['params']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"RF tuning failed with error: {str(e)}\")\n",
    "    print(f\"Error during RF tuning: {str(e)}\")\n",
    "\n",
    "# Print results\n",
    "rf_tuning_time = time.time() - start_time\n",
    "logger.info(f\"Random Forest tuning completed in {rf_tuning_time:.2f} seconds\")\n",
    "print(f\"\\nRandom Forest tuning completed in {rf_tuning_time:.2f} seconds\")\n",
    "print(f\"Best MSE: {-rf_random_search.best_score_:.4f}\")\n",
    "print(\"Best Random Forest Parameters:\")\n",
    "for param, value in rf_random_search.best_params_.items():\n",
    "    print(f\"    {param}: {value}\")\n",
    "    logger.info(f\"Best {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fit the XGBoost model with Bayesian optimization\n",
    "    xgb_bayes_search.fit(X_train_processed, y_train)\n",
    "    \n",
    "    # Store the optimization results\n",
    "    xgb_results = pd.DataFrame(xgb_bayes_search.cv_results_)\n",
    "    \n",
    "    # Log the top 5 best performing parameter combinations\n",
    "    logger.info(\"Top 5 XGBoost parameter combinations:\")\n",
    "    top_results = xgb_results.sort_values('mean_test_score', ascending=False).head(5)\n",
    "    for i, row in top_results.iterrows():\n",
    "        logger.info(f\"Rank {i+1}: Score = {-row['mean_test_score']:.4f}, Params = {row['params']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.error(f\"XGB Bayesian optimization failed with error: {str(e)}\")\n",
    "    print(f\"Error during XGB Bayesian optimization: {str(e)}\")\n",
    "\n",
    "# Print results\n",
    "xgb_tuning_time = time.time() - start_time\n",
    "logger.info(f\"XGBoost Bayesian optimization completed in {xgb_tuning_time:.2f} seconds\")\n",
    "print(f\"\\nXGBoost Bayesian optimization completed in {xgb_tuning_time:.2f} seconds\")\n",
    "print(f\"Best MSE: {-xgb_bayes_search.best_score_:.4f}\")\n",
    "print(\"Best XGBoost Parameters:\")\n",
    "for param, value in xgb_bayes_search.best_params_.items():\n",
    "    print(f\"    {param}: {value}\")\n",
    "    logger.info(f\"Best {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best models and save results\n",
    "tuned_rf = rf_random_search.best_estimator_\n",
    "tuned_xgb = xgb_bayes_search.best_estimator_\n",
    "\n",
    "# Create timestamp for unique filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save detailed tuning results to CSV for later analysis\n",
    "rf_results.to_csv(f\"{checkpoint_dir}/rf_tuning_results_{timestamp}.csv\", index=False)\n",
    "xgb_results.to_csv(f\"{checkpoint_dir}/xgb_bayes_tuning_results_{timestamp}.csv\", index=False)\n",
    "logger.info(f\"Tuning results saved to CSV files in {checkpoint_dir}\")\n",
    "\n",
    "# Save the tuned models\n",
    "tuned_rf_path = os.path.join(checkpoint_dir, f'rf_model_tuned_{timestamp}.pkl')\n",
    "with open(tuned_rf_path, 'wb') as f:\n",
    "    pickle.dump(tuned_rf, f)\n",
    "print(f\"Tuned Random Forest model saved to {tuned_rf_path}\")\n",
    "\n",
    "tuned_xgb_path = os.path.join(checkpoint_dir, f'xgb_model_tuned_{timestamp}.pkl')\n",
    "with open(tuned_xgb_path, 'wb') as f:\n",
    "    pickle.dump(tuned_xgb, f)\n",
    "print(f\"Tuned XGBoost model saved to {tuned_xgb_path}\")\n",
    "\n",
    "# Calculate R² scores on validation data\n",
    "rf_val_pred = tuned_rf.predict(X_val_processed)\n",
    "xgb_val_pred = tuned_xgb.predict(X_val_processed)\n",
    "rf_r2 = r2_score(y_val, rf_val_pred)\n",
    "xgb_r2 = r2_score(y_val, xgb_val_pred)\n",
    "\n",
    "print(\"\\nHyperparameter tuning complete!\")\n",
    "print(f\"Best Random Forest model:\")\n",
    "print(f\"  - MSE: {-rf_random_search.best_score_:.4f}\")\n",
    "print(f\"  - R²: {rf_r2:.4f}\")\n",
    "print(f\"Best XGBoost model:\")\n",
    "print(f\"  - MSE: {-xgb_bayes_search.best_score_:.4f}\")\n",
    "print(f\"  - R²: {xgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenomenal results, we have improved the model by a large amount. The model is now able to predict the bike rentals with a high degree of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evalutaion/Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try and find some interactions that might be useful for the model. Adding all possible interactions, will be evaluated and dropped if under certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the top of Section 8 (Evaluation/Refinement)\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL REFINEMENT AND FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract available column names from processed DataFrames\n",
    "available_columns = X_train_processed.columns.tolist()\n",
    "print(f\"Available columns: {available_columns}\")\n",
    "\n",
    "# Create copies for interaction features\n",
    "X_train_interactions = X_train_processed.copy()\n",
    "X_val_interactions = X_val_processed.copy()\n",
    "X_test_interactions = X_test_processed.copy()\n",
    "\n",
    "# 1. Add interaction between temperature and humidity if available\n",
    "if 'temp' in available_columns and 'hum' in available_columns:\n",
    "    print(\"Adding temp × humidity interaction feature\")\n",
    "    X_train_interactions['temp_hum_interaction'] = X_train_interactions['temp'] * X_train_interactions['hum']\n",
    "    X_val_interactions['temp_hum_interaction'] = X_val_interactions['temp'] * X_val_interactions['hum']\n",
    "    X_test_interactions['temp_hum_interaction'] = X_test_interactions['temp'] * X_test_interactions['hum']\n",
    "else:\n",
    "    print(\"Skipping temperature × humidity interaction (required columns not available)\")\n",
    "\n",
    "# 2. Add additional interaction for time of day and weather\n",
    "if 'hr_sin' in available_columns and 'weather_severity' in available_columns:\n",
    "    print(\"Adding hour (cyclical) × weather interaction features\")\n",
    "    X_train_interactions['hr_sin_weather'] = X_train_interactions['hr_sin'] * X_train_interactions['weather_severity']\n",
    "    X_val_interactions['hr_sin_weather'] = X_val_interactions['hr_sin'] * X_val_interactions['weather_severity']\n",
    "    X_test_interactions['hr_sin_weather'] = X_test_interactions['hr_sin'] * X_test_interactions['weather_severity']\n",
    "else:\n",
    "    print(\"Skipping hour × weather interaction (required columns not available)\")\n",
    "\n",
    "# 3. Add season-related interactions\n",
    "season_cols = [col for col in available_columns if 'season' in col]\n",
    "if 'temp' in available_columns and season_cols:\n",
    "    print(\"Adding season × temperature interactions for columns:\", season_cols)\n",
    "    for season_col in season_cols:\n",
    "        X_train_interactions[f'{season_col}_temp'] = X_train_interactions[season_col] * X_train_interactions['temp']\n",
    "        X_val_interactions[f'{season_col}_temp'] = X_val_interactions[season_col] * X_val_interactions['temp']\n",
    "        X_test_interactions[f'{season_col}_temp'] = X_test_interactions[season_col] * X_test_interactions['temp']\n",
    "else:\n",
    "    print(\"Skipping season × temperature interactions (required columns not available)\")\n",
    "\n",
    "# 4. Create squared terms for important numerical features\n",
    "for col in ['temp', 'hum', 'windspeed']:\n",
    "    if col in available_columns:\n",
    "        print(f\"Adding squared term for {col}\")\n",
    "        X_train_interactions[f'{col}_squared'] = X_train_interactions[col] ** 2\n",
    "        X_val_interactions[f'{col}_squared'] = X_val_interactions[col] ** 2\n",
    "        X_test_interactions[f'{col}_squared'] = X_test_interactions[col] ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a NEW model with refined features rather than using the previously tuned model\n",
    "# This is the key fix - don't use tuned_xgb which expects the original feature set\n",
    "print(f\"\\nTraining refined model with {X_train_interactions.shape[1]} features (added {X_train_interactions.shape[1] - X_train_processed.shape[1]} interaction features)\")\n",
    "\n",
    "# Create a new model with the same hyperparameters as the tuned model\n",
    "refined_model = XGBRegressor(**xgb_bayes_search.best_params_, random_state=42)\n",
    "refined_model.fit(X_train_interactions, y_train)\n",
    "\n",
    "# Make predictions with the refined model\n",
    "y_train_pred_refined = refined_model.predict(X_train_interactions)\n",
    "y_val_pred_refined = refined_model.predict(X_val_interactions)\n",
    "\n",
    "# Calculate metrics with the refined model\n",
    "refined_metrics = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred_refined),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred_refined),\n",
    "    'R2': r2_score(y_val, y_val_pred_refined)\n",
    "}\n",
    "\n",
    "print(\"\\nRefined Model Validation Metrics:\")\n",
    "for metric, value in refined_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Compare with base tuned model without interactions\n",
    "print(\"\\nImprovement over base tuned model:\")\n",
    "base_tuned_preds = tuned_xgb.predict(X_val_processed)\n",
    "base_metrics = {\n",
    "    'MSE': mean_squared_error(y_val, base_tuned_preds),\n",
    "    'MAE': mean_absolute_error(y_val, base_tuned_preds),\n",
    "    'R2': r2_score(y_val, base_tuned_preds)\n",
    "}\n",
    "\n",
    "for metric in refined_metrics:\n",
    "    improvement = (refined_metrics[metric] - base_metrics[metric]) / abs(base_metrics[metric]) * 100\n",
    "    better_worse = \"better\" if (metric == \"R2\" and improvement > 0) or (metric != \"R2\" and improvement < 0) else \"worse\"\n",
    "    print(f\"{metric}: {improvement:.2f}% {better_worse}\")\n",
    "\n",
    "# Save the model with interaction features\n",
    "refined_model_path = os.path.join(checkpoint_dir, 'xgb_model_with_interactions.pkl')\n",
    "with open(refined_model_path, 'wb') as f:\n",
    "    pickle.dump(refined_model, f)\n",
    "print(f\"XGBoost model with interactions saved to {refined_model_path}\")\n",
    "\n",
    "# Plot feature importance of the refined model\n",
    "plt.figure(figsize=(12, 10))\n",
    "feature_importance = pd.Series(refined_model.feature_importances_, index=X_train_interactions.columns).sort_values(ascending=False)\n",
    "top_features = feature_importance.head(15)\n",
    "top_features.plot.barh()\n",
    "plt.title('Top 15 Features in Refined Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the interacions show worse performance we will drop badly erforming features to improve the model performance. None of the interactions seem to be more important than the original features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Drop Poorly Performing Features and Retrain Models\n",
    "\n",
    "Based on the feature importance analysis from our Random Forest model, some features show significantly lower importance compared to others. Let's identify these poorly performing features, drop them, and then retrain both our Linear Regression and Random Forest models to see if we can improve performance by removing noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance from the refined model\n",
    "feature_importance = pd.Series(refined_model.feature_importances_, \n",
    "                             index=X_train_interactions.columns).sort_values()\n",
    "\n",
    "# Plot the 10 least important features\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance.head(10).plot(kind='barh')\n",
    "plt.title('10 Least Important Features')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify features with very low importance (using a threshold)\n",
    "importance_threshold = 0.01  # 1% importance threshold\n",
    "low_importance_features = feature_importance[feature_importance < importance_threshold].index.tolist()\n",
    "\n",
    "print(f\"Features with importance below {importance_threshold:.2f}:\")\n",
    "for feature in low_importance_features:\n",
    "    print(f\"  - {feature}: {feature_importance[feature]:.6f}\")\n",
    "\n",
    "print(f\"\\nNumber of features to drop: {len(low_importance_features)} out of {len(feature_importance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the datasets with low importance features removed\n",
    "X_train_reduced = X_train_interactions.drop(columns=low_importance_features)\n",
    "X_val_reduced = X_val_interactions.drop(columns=low_importance_features)\n",
    "X_test_reduced = X_test_interactions.drop(columns=low_importance_features)\n",
    "\n",
    "print(f\"Original feature count: {X_train_interactions.shape[1]}\")\n",
    "print(f\"Reduced feature count: {X_train_reduced.shape[1]}\")\n",
    "print(f\"Features dropped: {X_train_interactions.shape[1] - X_train_reduced.shape[1]}\")\n",
    "\n",
    "# Display remaining features\n",
    "print(\"\\nRemaining features:\")\n",
    "print(X_train_reduced.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Retrain Linear Regression with Reduced Features\n",
    "\n",
    "Let's retrain our Linear Regression model with the reduced feature set and compare its performance with the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain Linear Regression model with reduced features\n",
    "lr_model_reduced = LinearRegression()\n",
    "lr_model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lr_reduced = lr_model_reduced.predict(X_train_reduced)\n",
    "y_val_pred_lr_reduced = lr_model_reduced.predict(X_val_reduced)\n",
    "\n",
    "# Calculate metrics for reduced feature model\n",
    "lr_reduced_metrics = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred_lr_reduced),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred_lr_reduced),\n",
    "    'R2': r2_score(y_val, y_val_pred_lr_reduced)\n",
    "}\n",
    "\n",
    "# Compare with the original Linear Regression model\n",
    "print(\"Linear Regression Performance Comparison:\")\n",
    "print(f\"{'Metric':<15} {'Original':<15} {'Reduced Features':<15} {'Improvement':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['MSE', 'MAE', 'R2']:\n",
    "    if metric in metrics and metric in lr_reduced_metrics:\n",
    "        improvement = (lr_reduced_metrics[metric] - metrics[metric]) / abs(metrics[metric]) * 100\n",
    "        better_worse = \"better\" if ((metric == \"R2\" and improvement > 0) or \n",
    "                                 (metric != \"R2\" and improvement < 0)) else \"worse\"\n",
    "        print(f\"{metric:<15} {metrics[metric]:<15.4f} {lr_reduced_metrics[metric]:<15.4f} {improvement:+.2f}% ({better_worse})\")\n",
    "        \n",
    "# Plot residuals for the reduced model\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals_lr_reduced = y_val - y_val_pred_lr_reduced\n",
    "sns.histplot(residuals_lr_reduced, kde=True)\n",
    "plt.title('Distribution of Residuals (Linear Regression - Reduced Features)')\n",
    "plt.xlabel('Residual Value')\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Retrain Random Forest with Reduced Features\n",
    "\n",
    "Now let's retrain the Random Forest model with the reduced feature set and compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain Random Forest model with reduced features\n",
    "rf_model_reduced = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_rf_reduced = rf_model_reduced.predict(X_train_reduced)\n",
    "y_val_pred_rf_reduced = rf_model_reduced.predict(X_val_reduced)\n",
    "\n",
    "# Calculate metrics for reduced feature model\n",
    "rf_reduced_metrics = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred_rf_reduced),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred_rf_reduced),\n",
    "    'R2': r2_score(y_val, y_val_pred_rf_reduced)\n",
    "}\n",
    "\n",
    "# Compare with the original Random Forest model\n",
    "print(\"Random Forest Performance Comparison:\")\n",
    "print(f\"{'Metric':<15} {'Original':<15} {'Reduced Features':<15} {'Improvement':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['MSE', 'MAE', 'R2']:\n",
    "    if metric in metrics_rf and metric in rf_reduced_metrics:\n",
    "        improvement = (rf_reduced_metrics[metric] - metrics_rf[metric]) / abs(metrics_rf[metric]) * 100\n",
    "        better_worse = \"better\" if ((metric == \"R2\" and improvement > 0) or \n",
    "                                 (metric != \"R2\" and improvement < 0)) else \"worse\"\n",
    "        print(f\"{metric:<15} {metrics_rf[metric]:<15.4f} {rf_reduced_metrics[metric]:<15.4f} {improvement:+.2f}% ({better_worse})\")\n",
    "\n",
    "# Plot feature importance for the reduced Random Forest model\n",
    "plt.figure(figsize=(12, 8))\n",
    "rf_reduced_importance = pd.Series(rf_model_reduced.feature_importances_, \n",
    "                              index=X_train_reduced.columns).sort_values(ascending=False)\n",
    "rf_reduced_importance.head(10).plot(kind='barh')\n",
    "plt.title('Top 10 Features in Reduced Random Forest Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the interactions are aiding model prediction but due to an overall decrease in performance we will not use them for random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Retrain Gradient Boosting with Reduced Features\n",
    "Now let's retrain the Gradient Boosting model with the reduced feature set and compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain XGBoost model with reduced features\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Create a new XGBoost model with the best parameters found during hyperparameter tuning\n",
    "xgb_model_reduced = XGBRegressor(**xgb_bayes_search.best_params_, random_state=42)\n",
    "\n",
    "# Train the model on the reduced feature set\n",
    "print(\"Training XGBoost model with reduced features...\")\n",
    "xgb_model_reduced.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_xgb_reduced = xgb_model_reduced.predict(X_train_reduced)\n",
    "y_val_pred_xgb_reduced = xgb_model_reduced.predict(X_val_reduced)\n",
    "\n",
    "# Calculate metrics for reduced feature model\n",
    "xgb_reduced_metrics = {\n",
    "    'MSE': mean_squared_error(y_val, y_val_pred_xgb_reduced),\n",
    "    'MAE': mean_absolute_error(y_val, y_val_pred_xgb_reduced),\n",
    "    'R2': r2_score(y_val, y_val_pred_xgb_reduced)\n",
    "}\n",
    "\n",
    "# Compare with the original XGBoost model\n",
    "print(\"\\nXGBoost Performance Comparison:\")\n",
    "print(f\"{'Metric':<15} {'Original':<15} {'Reduced Features':<15} {'Improvement':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['MSE', 'MAE', 'R2']:\n",
    "    if metric in val_metrics and metric in xgb_reduced_metrics:\n",
    "        improvement = (xgb_reduced_metrics[metric] - val_metrics[metric]) / abs(val_metrics[metric]) * 100\n",
    "        better_worse = \"better\" if ((metric == \"R2\" and improvement > 0) or \n",
    "                                   (metric != \"R2\" and improvement < 0)) else \"worse\"\n",
    "        print(f\"{metric:<15} {val_metrics[metric]:<15.4f} {xgb_reduced_metrics[metric]:<15.4f} {improvement:+.2f}% ({better_worse})\")\n",
    "\n",
    "# Plot feature importance for the reduced XGBoost model\n",
    "plt.figure(figsize=(12, 8))\n",
    "xgb_reduced_importance = pd.Series(xgb_model_reduced.feature_importances_, \n",
    "                             index=X_train_reduced.columns).sort_values(ascending=False)\n",
    "xgb_reduced_importance.head(10).plot(kind='barh')\n",
    "plt.title('Top 10 Features in Reduced XGBoost Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the reduced feature XGBoost model\n",
    "reduced_xgb_model_path = os.path.join(checkpoint_dir, 'xgb_model_reduced.pkl')\n",
    "with open(reduced_xgb_model_path, 'wb') as f:\n",
    "    pickle.dump(xgb_model_reduced, f)\n",
    "\n",
    "print(f\"Reduced XGBoost model saved to {reduced_xgb_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with interactions performing badly dropped, the model still performs worse overall. As such we will continue with the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Model\n",
    "\n",
    "I haverun this with the reduced model, it was indeed overfitting and resulted in worse performance, as such I am going to use the original model with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL MODEL IMPLEMENTATION AND EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# We'll use the original processed features where the model achieved 0.90+ R²\n",
    "# Combine training and validation sets for final training\n",
    "X_final_train = pd.concat([X_train_processed, X_val_processed])\n",
    "y_final_train = pd.concat([y_train, y_val])\n",
    "\n",
    "# Create a clean final model using the same hyperparameters as our best model\n",
    "final_model = XGBRegressor(**xgb_bayes_search.best_params_, random_state=42)\n",
    "\n",
    "# Print the best hyperparameters found during Bayesian optimization\n",
    "print(\"Best hyperparameters from Bayesian optimization:\")\n",
    "for param, value in xgb_bayes_search.best_params_.items():\n",
    "    print(f\"  - {param}: {value}\")\n",
    "\n",
    "# Train on the combined data\n",
    "print(\"\\nTraining final model on combined training and validation data...\")\n",
    "final_model.fit(X_final_train, y_final_train)\n",
    "\n",
    "# Make predictions on all three datasets to compare metrics\n",
    "train_preds = final_model.predict(X_train_processed)\n",
    "val_preds = final_model.predict(X_val_processed)\n",
    "test_preds = final_model.predict(X_test_processed)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, median_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, dataset_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    medae = median_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    explained_var = explained_variance_score(y_true, y_pred)\n",
    "    mean_abs_pct_error = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    metrics_dict = {\n",
    "        'Dataset': dataset_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'Median AE': medae,\n",
    "        'MAPE (%)': mean_abs_pct_error,\n",
    "        'R²': r2,\n",
    "        'Explained Variance': explained_var\n",
    "    }\n",
    "    return metrics_dict\n",
    "\n",
    "# Calculate metrics for all three datasets\n",
    "train_metrics = calculate_metrics(y_train, train_preds, \"Training\")\n",
    "val_metrics = calculate_metrics(y_val, val_preds, \"Validation\")\n",
    "test_metrics = calculate_metrics(y_test, test_preds, \"Test\")\n",
    "\n",
    "# Combine all metrics into a DataFrame for easier comparison\n",
    "all_metrics = pd.DataFrame([train_metrics, val_metrics, test_metrics])\n",
    "\n",
    "# Print the metrics table\n",
    "print(\"\\nComprehensive Model Performance Metrics:\")\n",
    "print(all_metrics.set_index('Dataset').round(4))\n",
    "\n",
    "# Calculate if the model tends to overpredict or underpredict\n",
    "avg_train_error = np.mean(y_train - train_preds)\n",
    "avg_val_error = np.mean(y_val - val_preds)\n",
    "avg_test_error = np.mean(y_test - test_preds)\n",
    "\n",
    "print(\"\\nPrediction Bias Analysis:\")\n",
    "print(f\"Average Train Error: {avg_train_error:.2f} ({'Underpredicts' if avg_train_error > 0 else 'Overpredicts'})\")\n",
    "print(f\"Average Validation Error: {avg_val_error:.2f} ({'Underpredicts' if avg_val_error > 0 else 'Overpredicts'})\")\n",
    "print(f\"Average Test Error: {avg_test_error:.2f} ({'Underpredicts' if avg_test_error > 0 else 'Overpredicts'})\")\n",
    "\n",
    "# Plot residuals vs predicted values to check for patterns\n",
    "plt.figure(figsize=(12, 8))\n",
    "residuals = y_test - test_preds\n",
    "plt.scatter(test_preds, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.title('Residuals vs Predicted Values (Test Set)', fontsize=14)\n",
    "plt.xlabel('Predicted Values', fontsize=12)\n",
    "plt.ylabel('Residuals', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{checkpoint_dir}/prediction_analysis.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot with 45-degree line for actual vs predicted\n",
    "plt.figure(figsize=(10, 8))\n",
    "max_val = max(max(y_test), max(test_preds))\n",
    "min_val = min(min(y_test), min(test_preds))\n",
    "plt.scatter(y_test, test_preds, alpha=0.5)\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "plt.title('Actual vs Predicted Values (Test Set)', fontsize=14)\n",
    "plt.xlabel('Actual Values', fontsize=12)\n",
    "plt.ylabel('Predicted Values', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add error distribution histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.title('Distribution of Prediction Errors (Test Set)', fontsize=14)\n",
    "plt.xlabel('Prediction Error', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and visualize feature importance\n",
    "plt.figure(figsize=(14, 10))\n",
    "feature_importance = pd.Series(final_model.feature_importances_, \n",
    "                              index=X_final_train.columns).sort_values(ascending=False)\n",
    "top_features = feature_importance.head(15)\n",
    "ax = top_features.plot(kind='barh', color=sns.color_palette(\"viridis\", len(top_features)))\n",
    "plt.title('Top 15 Most Important Features in Final Model', fontsize=14)\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "\n",
    "# Add value labels to the bars\n",
    "for i, v in enumerate(top_features):\n",
    "    ax.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the final model for future use\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_model_path = os.path.join(checkpoint_dir, 'bike_rental_final_model.pkl')\n",
    "with open(final_model_path, 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_names_path = os.path.join(checkpoint_dir, 'model_feature_names.txt')\n",
    "with open(feature_names_path, 'w') as f:\n",
    "    f.write('\\n'.join(X_final_train.columns.tolist()))\n",
    "\n",
    "print(f\"\\nFinal model saved to {final_model_path}\")\n",
    "print(f\"Feature names saved to {feature_names_path}\")\n",
    "\n",
    "# Print a summary of the model and its performance\n",
    "print(\"\\nFINAL MODEL SUMMARY:\")\n",
    "print(f\"- Algorithm: XGBoost Regression with Bayesian-optimized hyperparameters\")\n",
    "print(f\"- Training data: {X_final_train.shape[0]} samples, {X_final_train.shape[1]} features\")\n",
    "print(f\"- Test performance: R² = {test_metrics['R²']:.4f}, RMSE = {test_metrics['RMSE']:.2f}\")\n",
    "print(f\"- Top 3 most important features: {', '.join(top_features.index[:3])}\")\n",
    "print(f\"- Prediction bias: Model tends to {'underpredict' if avg_test_error > 0 else 'overpredict'} by {abs(avg_test_error):.2f} rentals on average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs the best out of all the models we have trained. It has the lowest RMSE and MAE on the test set, indicating that it is the most accurate model for predicting bike rentals.\n",
    "Although it does generall underpredict this is expected as the data used for training contains a slow increase in bike rentals over time. This is not very reflected in the training data as there is a near doubling in rentals from one year to the next.\n",
    "An 86% accuracy is very good for this model, and I am happy with the results. I will be using this model for my final submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
